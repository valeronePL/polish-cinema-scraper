# .github/workflows/daily-cinema-scrape.yml
# Automated daily scraping of Polish cinema schedules
# Sources:
#   - kino.coigdzie.pl (aggregator - all chains)
#   - helios.pl (special events: pre-premieres, kids)
#   - Cinema City API (official API with seat availability)
# Runs at 6:00 AM CET (5:00 AM UTC) every day

name: Daily Cinema Scrape

on:
  schedule:
    # Every day at 5:00 AM UTC (6:00 AM CET)
    - cron: '0 5 * * *'

  workflow_dispatch:
    inputs:
      date:
        description: 'Specific date (YYYY-MM-DD), leave empty for today'
        required: false
        default: ''

concurrency:
  group: cinema-scrape
  cancel-in-progress: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install requests beautifulsoup4 pandas lxml gspread

      - name: Create data directories
        run: mkdir -p data/daily cinema_data

      - name: Determine scrape date
        id: date
        run: |
          if [ -z "${{ github.event.inputs.date }}" ]; then
            SCRAPE_DATE=$(date +%Y-%m-%d)
          else
            SCRAPE_DATE="${{ github.event.inputs.date }}"
          fi
          echo "Scraping for date: $SCRAPE_DATE"
          echo "scrape_date=$SCRAPE_DATE" >> "$GITHUB_OUTPUT"

      - name: Run main scraper (kino.coigdzie.pl)
        working-directory: ${{ github.workspace }}
        env:
          PYTHONPATH: src
        run: |
          echo "ðŸŽ¬ Scraping kino.coigdzie.pl..."
          python3 src/kino_scraper_v2.py

      - name: Run Helios events scraper
        working-directory: ${{ github.workspace }}
        env:
          PYTHONPATH: src
        run: |
          echo "ðŸŽ­ Scraping Helios special events..."
          python3 src/helios_scraper.py || echo "Helios scraper completed with warnings"

      - name: Run Cinema City API scraper
        working-directory: ${{ github.workspace }}
        env:
          PYTHONPATH: src
        run: |
          echo "ðŸŽ¬ Scraping Cinema City API..."
          python3 src/cinema_city_scraper.py || echo "Cinema City scraper completed with warnings"

      - name: Merge all cinema data
        working-directory: ${{ github.workspace }}
        env:
          PYTHONPATH: src
        run: |
          echo "ðŸ”„ Merging data sources..."
          python3 src/merge_and_update.py --dates ${{ steps.date.outputs.scrape_date }} --no-sheets

          # Move merged output to data/daily
          mv cinema_data/*.json data/daily/ 2>/dev/null || true
          mv cinema_data/*.csv data/daily/ 2>/dev/null || true

      - name: Update Google Sheets
        env:
          GOOGLE_SERVICE_ACCOUNT: ${{ secrets.GOOGLE_SERVICE_ACCOUNT }}
          GOOGLE_SPREADSHEET_ID: ${{ secrets.GOOGLE_SPREADSHEET_ID }}
        run: |
          mkdir -p ~/.config/gspread
          echo "$GOOGLE_SERVICE_ACCOUNT" > ~/.config/gspread/service_account.json

          # Find the merged CSV for today
          SCRAPE_DATE=${{ steps.date.outputs.scrape_date }}
          CSV_FILE="data/daily/cinema_${SCRAPE_DATE}.csv"

          if [ ! -f "$CSV_FILE" ]; then
            # Fallback to most recent CSV
            CSV_FILE=$(ls -t data/daily/*.csv | head -1)
          fi

          echo "Uploading to Google Sheets: $CSV_FILE"
          python3 src/sheets_updater.py --csv "$CSV_FILE" --date "$SCRAPE_DATE"

      - name: Generate summary
        run: |
          echo "## ðŸŽ¬ Cinema Scrape Summary" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "**Date:** ${{ steps.date.outputs.scrape_date }}" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"

          CSV_FILE="data/daily/cinema_${{ steps.date.outputs.scrape_date }}.csv"
          if [ ! -f "$CSV_FILE" ]; then
            CSV_FILE=$(ls -t data/daily/*.csv 2>/dev/null | head -1)
          fi

          if [ -f "$CSV_FILE" ]; then
            ROWS=$(wc -l < "$CSV_FILE")
            CITIES=$(cut -d',' -f3 "$CSV_FILE" | tail -n +2 | sort -u | wc -l)
            MOVIES=$(cut -d',' -f4 "$CSV_FILE" | tail -n +2 | sort -u | wc -l)
            HELIOS=$(grep -ic "helios" "$CSV_FILE" || echo "0")
            CINEMA_CITY=$(grep -ic "cinema city\|cinema-city" "$CSV_FILE" || echo "0")

            echo "| Metric | Count |" >> "$GITHUB_STEP_SUMMARY"
            echo "|--------|-------|" >> "$GITHUB_STEP_SUMMARY"
            echo "| Total Screenings | $ROWS |" >> "$GITHUB_STEP_SUMMARY"
            echo "| Cities | $CITIES |" >> "$GITHUB_STEP_SUMMARY"
            echo "| Movies | $MOVIES |" >> "$GITHUB_STEP_SUMMARY"
            echo "| Helios Entries | $HELIOS |" >> "$GITHUB_STEP_SUMMARY"
            echo "| Cinema City Entries | $CINEMA_CITY |" >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Commit results
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"

          git add data/ src/

          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            COMMIT_DATE=${{ steps.date.outputs.scrape_date }}
            git commit -m "Daily scrape: $COMMIT_DATE (incl. Helios events)"
            git push
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: cinema-data-${{ steps.date.outputs.scrape_date }}
          path: data/daily/
          retention-days: 90
